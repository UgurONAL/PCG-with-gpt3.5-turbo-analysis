{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import related libraries",
   "id": "cf7bc5b5b89caa75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:56:27.943772Z",
     "start_time": "2024-06-10T10:56:27.152127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "import openai\n",
    "from src.experiment_analysis import *\n",
    "import random"
   ],
   "id": "5a95bd77bda58bde",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You must add your own OpenAI API key to the `openai-api-key.txt` file.",
   "id": "24cc3d6e69b853f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:56:27.951034Z",
     "start_time": "2024-06-10T10:56:27.946184Z"
    }
   },
   "cell_type": "code",
   "source": "api_key = get_file_contents(\"openai-api-key.txt\")",
   "id": "1d499ba89790ff45",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialize the OpenAI API Client with the API key",
   "id": "f9dd27be191bafa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:56:27.957737Z",
     "start_time": "2024-06-10T10:56:27.953011Z"
    }
   },
   "cell_type": "code",
   "source": "openai.api_key = api_key",
   "id": "f4ad8a45d0cc0de4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set your training mode for the fine-tuning process, all files related to this mode will have the name of the mode in their names.",
   "id": "3f08dedf5e09d8bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:56:27.965889Z",
     "start_time": "2024-06-10T10:56:27.961715Z"
    }
   },
   "cell_type": "code",
   "source": "train_mode = \"100-input-10-epoch-0.5-temp-50-output\"",
   "id": "da27656657abf5eb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get hyperparameters for the fine-tuning process",
   "id": "d2790e99853bec1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:56:28.041738Z",
     "start_time": "2024-06-10T10:56:27.967772Z"
    }
   },
   "cell_type": "code",
   "source": "hypers = read_hypers()",
   "id": "1cc45c32a6f5f79f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert training data to JSONL format",
   "id": "efe9e08673ea5ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T10:56:28.074942Z",
     "start_time": "2024-06-10T10:56:28.043642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_data_folder = f\"data/training_data/{hypers[train_mode][\"training_set\"]}\"\n",
    "training_data_path = f\"{training_data_folder}/training_data.jsonl\"\n",
    "create_jsonl_from_folder(training_data_folder, training_data_path)"
   ],
   "id": "7d56951715ee81ed",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Upload the training file to the API for fine-tuning purposes",
   "id": "879e101777d489a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-10T10:56:28.077685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(training_data_path, \"r\") as file:\n",
    "    response = openai.File.create(file=file, purpose=\"fine-tune\")\n",
    "\n",
    "file_id = response[\"id\"]\n",
    "write_file_contents(f\"data/client_file_ids/{train_mode}.txt\", file_id)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set the base model to fine-tune. gpt-3.5-turbo-0125 is the currently recommended model.",
   "id": "42ccbbf0ec55905c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "base_model = \"gpt-3.5-turbo-0125\"",
   "id": "9c6e0e76b914895e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a fine-tuning job for the model with the training file",
   "id": "546eeec4bb611878"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_file_id = get_file_contents(f\"data/client_file_ids/{train_mode}.txt\")\n",
    "\n",
    "response = openai.FineTuningJob.create(\n",
    "    model=base_model,\n",
    "    training_file=training_file_id,\n",
    "    suffix=train_mode.replace(\"-input\", \"\").replace(\"-epoch\", \"\").replace(\"-temp\", \"\").replace(\"-output\", \"\"),\n",
    "    hyperparameters={\"n_epochs\": hypers[train_mode][\"n_epochs\"]}\n",
    ")\n",
    "\n",
    "fine_tuning_job_id = response[\"id\"]\n",
    "write_file_contents(f\"data/fine_tuning_job_ids/{train_mode}.txt\", fine_tuning_job_id)"
   ],
   "id": "b281b242884cbd3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generate levels using the fine-tuned model",
   "id": "b4a16dade82d9ba5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fine_tuning_job_id = get_file_contents(f\"data/fine_tuning_job_ids/{train_mode}.txt\")\n",
    "fine_tuning_job = openai.FineTuningJob.retrieve(id=fine_tuning_job_id)\n",
    "\n",
    "fine_tuning_status = fine_tuning_job.status\n",
    "if fine_tuning_status == \"succeeded\":\n",
    "    fine_tuned_model = fine_tuning_job.fine_tuned_model\n",
    "    \n",
    "    for i in range(hypers[train_mode][\"n_generations\"]):\n",
    "        m = random.randint(7, 35)\n",
    "        n = random.randint(8, 35)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=fine_tuned_model,\n",
    "            messages=get_messages_for_chat_completion(m, n),\n",
    "            temperature=hypers[train_mode][\"temperature\"],\n",
    "        )\n",
    "        generated_level = response.choices[0].message[\"content\"]\n",
    "        \n",
    "        generated_level_folder = f\"data/generated_levels/{train_mode}\"\n",
    "        if not os.path.exists(generated_level_folder):\n",
    "            os.makedirs(generated_level_folder)\n",
    "        write_file_contents(f\"{generated_level_folder}/level_{i}_{m}x{n}.txt\", generated_level)\n",
    "        print(f\"Generated level {i} with dimensions {m}x{n} for {train_mode}\")\n",
    "else:\n",
    "    print(f\"Fine-tuning job {fine_tuning_job_id} has not succeeded yet. Current status: {fine_tuning_status}\")"
   ],
   "id": "87c91c8fb3060792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Get all experiments analysis",
   "id": "299161d9eab58916"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T13:06:46.627393Z",
     "start_time": "2024-06-10T13:06:45.088135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.experiment_analysis import *\n",
    "experiment_results = analyse_all_experiment_results(os.path.abspath(\"data\"))\n",
    "store_experiment_results(experiment_results, os.path.abspath(\"experimental_analysis\"))\n",
    "visualize_experiment_results(experiment_results, os.path.abspath(\"experimental_analysis\"))"
   ],
   "id": "3fc79e81e2fd83e4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ugur/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/venv/lib/python3.12/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/home/ugur/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/venv/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T12:40:12.101159Z",
     "start_time": "2024-06-10T12:40:00.755648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utilities import *\n",
    "filename1 = \"data/generated_levels/200-input-3-epoch-0.5-temp-50-output/level_0_8x12.txt\"\n",
    "filename2 = \"data/training_data/training-set-200-examples/Sasquatch_level_1.txt\"\n",
    "intended_dimensions = tuple(filename1.split(\"_\")[-1].split(\".\")[0].split(\"x\"))\n",
    "print(check_level_validity(read_level_from_txt(filename2), (11, 11)))\n",
    "print(check_level_validity(read_level_from_txt(filename1), intended_dimensions))"
   ],
   "id": "6f83ad0949bc61aa",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m filename2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/training_data/training-set-200-examples/Sasquatch_level_1.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m intended_dimensions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(filename1\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcheck_level_validity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mread_level_from_txt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename2\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m11\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m11\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(check_level_validity(read_level_from_txt(filename1), intended_dimensions))\n",
      "File \u001B[0;32m~/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/src/utilities.py:180\u001B[0m, in \u001B[0;36mcheck_level_validity\u001B[0;34m(level_matrix, intended_dimensions, check_solvable)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_solvable \u001B[38;5;129;01mand\u001B[39;00m player_count_check \u001B[38;5;129;01mand\u001B[39;00m crate_storage_location_count_check:\n\u001B[1;32m    179\u001B[0m     sokoban_solver \u001B[38;5;241m=\u001B[39m SokobanSolver(level_matrix)\n\u001B[0;32m--> 180\u001B[0m     solvable_check \u001B[38;5;241m=\u001B[39m \u001B[43msokoban_solver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    181\u001B[0m     solution \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m solvable_check:\n",
      "File \u001B[0;32m~/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/src/sokoban_solver.py:133\u001B[0m, in \u001B[0;36mSokobanSolver.solve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msolve\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 133\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolution_node \u001B[38;5;241m=\u001B[39m \u001B[43mastar_search\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolution_node \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/src/search.py:423\u001B[0m, in \u001B[0;36mastar_search\u001B[0;34m(problem, h, display)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"A* search is best-first graph search with f(n) = g(n)+h(n).\u001B[39;00m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;124;03mYou need to specify the h function when you call astar_search, or\u001B[39;00m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;124;03melse in your Problem subclass.\"\"\"\u001B[39;00m\n\u001B[1;32m    422\u001B[0m h \u001B[38;5;241m=\u001B[39m memoize(h \u001B[38;5;129;01mor\u001B[39;00m problem\u001B[38;5;241m.\u001B[39mh, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mh\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 423\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbest_first_graph_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproblem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath_cost\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mh\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisplay\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/src/search.py:284\u001B[0m, in \u001B[0;36mbest_first_graph_search\u001B[0;34m(problem, f, display)\u001B[0m\n\u001B[1;32m    282\u001B[0m explored\u001B[38;5;241m.\u001B[39madd(node\u001B[38;5;241m.\u001B[39mstate)\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m child \u001B[38;5;129;01min\u001B[39;00m node\u001B[38;5;241m.\u001B[39mexpand(problem):\n\u001B[0;32m--> 284\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m child\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m explored \u001B[38;5;129;01mand\u001B[39;00m \u001B[43mchild\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfrontier\u001B[49m:\n\u001B[1;32m    285\u001B[0m         frontier\u001B[38;5;241m.\u001B[39mappend(child)\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m child \u001B[38;5;129;01min\u001B[39;00m frontier:\n",
      "File \u001B[0;32m~/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/src/utils.py:766\u001B[0m, in \u001B[0;36mPriorityQueue.__contains__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__contains__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):\n\u001B[1;32m    765\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return True if the key is in PriorityQueue.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 766\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28many\u001B[39m([\u001B[43mitem\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _, item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mheap])\n",
      "File \u001B[0;32m~/Desktop/Academy/BLG 521E AI/Project/Code/PCG-with-gpt3.5-turbo-analysis/src/search.py:125\u001B[0m, in \u001B[0;36mNode.__eq__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mreversed\u001B[39m(path_back))\n\u001B[1;32m    120\u001B[0m \u001B[38;5;66;03m# We want for a queue of nodes in breadth_first_graph_search or\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# astar_search to have no duplicated states, so we treat nodes\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;66;03m# with the same state as equal. [Problem: this may not be what you\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# want in other contexts.]\u001B[39;00m\n\u001B[0;32m--> 125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__eq__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, Node) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m other\u001B[38;5;241m.\u001B[39mstate\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__hash__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;66;03m# We use the hash value of the state\u001B[39;00m\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;66;03m# stored in the node instead of the node\u001B[39;00m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# object itself to quickly search a node\u001B[39;00m\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;66;03m# with the same state in a Hash Table\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "aa6c827a63a48478",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
